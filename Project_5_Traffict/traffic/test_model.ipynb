{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_main_folder = 'gtsrb'\n",
    "EPOCHS = 10\n",
    "IMG_WIDTH = 30\n",
    "IMG_HEIGHT = 30\n",
    "NUM_CATEGORIES = 43\n",
    "TEST_SIZE = 0.4\n",
    "X = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\"\n",
    "    Loads all the images into a list of numpy arrays\n",
    "    \"\"\"\n",
    "    folders = os.listdir(data_dir)\n",
    "    dimension = ( IMG_WIDTH, IMG_HEIGHT )\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in folders:\n",
    "        if folder.startswith('.'):\n",
    "            continue\n",
    "        image_names = os.listdir(os.path.join(data_dir, folder))\n",
    "        for image_name in image_names:\n",
    "            image = cv2.imread(os.path.join(data_dir, folder, image_name))\n",
    "            image = cv2.resize(image, dimension, interpolation = cv2.INTER_AREA)\n",
    "            images.append(image)\n",
    "            labels.append(folder)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data(images_main_folder)\n",
    "labels = tf.keras.utils.to_categorical(labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameters_combination(  combine:bool = False, \n",
    "                                    epochs:list = [EPOCHS], \n",
    "                                    batch_sizes:list = [25],\n",
    "                                    layers:list = [1], \n",
    "                                    nodes:list = [100], \n",
    "                                    node_variations:list = ['equal'], \n",
    "                                    dense_activations:list = ['relu'],\n",
    "                                    dropouts:list = [0.5], \n",
    "                                    kernel_sizes:list = [3], \n",
    "                                    kernel_tries:list = [32], \n",
    "                                    convolutionals:list = [1], \n",
    "                                    convolutional_activations:list = ['relu'],\n",
    "                                    max_pooling_sizes:list = [2] ) -> dict: \n",
    "    \"\"\"\n",
    "    This creates a set of dictionaries with the parameters for the creation of the model \n",
    "    and the training of the same.\n",
    "    Args:\n",
    "        combine: Default False, this decides if you make a combination of all parameters\n",
    "         or just set default for each one and iterate on one at the time. The default \n",
    "         value for each parameter is the firt item in the list.\n",
    "        epochs: number of epochs in which to train the mode. Is a list of integers.\n",
    "        batch_size: List of batch sizes.\n",
    "        layers: number of Dense layers to apply to the model. List of integers.\n",
    "        nodes: Total number of nodes for all layers. It will be rounded down if not divisible by \n",
    "         number of layers.\n",
    "        node_variation: Decides the amount of nodes per layer in weights, you can have a descending\n",
    "         amount per layer, an ascending amount, an interleaved, or an equal amount.\n",
    "        dense_activations: List with activation equation for hidden layers.\n",
    "        dropout: percentage of dropout for last layer.\n",
    "        kernel_size: Sice of kernel matrix.\n",
    "        kernel_tries: Amount of times a new kernel is tried.\n",
    "        convolutionals: List with amount of convolutional layers applied.\n",
    "        convolutional_activations: List with activation methods for the convolutional.\n",
    "        max_pooling_sizes: List with amount of max_pooling matrix size.\n",
    "    \"\"\"\n",
    "\n",
    "    available_node_variations = [ 'equal',\n",
    "                                'ascending',\n",
    "                                'descending',\n",
    "                                'interleaved']\n",
    "\n",
    "    for variation in node_variations:\n",
    "        if not variation in available_node_variations:\n",
    "            raise Exception(f'node variation not in options: Must choose {available_node_variations}')\n",
    "\n",
    "    parameters_list = []\n",
    "    for epoch in epochs:\n",
    "        first_epoch = epoch == epochs[0]\n",
    "        for batch_size in batch_sizes:\n",
    "            first_batch_size = batch_size == batch_sizes[0]\n",
    "            for layer in layers:\n",
    "                first_layer = layer == layers[0]\n",
    "                for node_num in nodes:\n",
    "                    first_node_num = node_num == nodes[0]\n",
    "                    for node_variation in node_variations:\n",
    "                        first_node_variation = node_variation == node_variations[0]\n",
    "                        for dense_activation in dense_activations:\n",
    "                            first_dense_activation = dense_activation == dense_activations[0]\n",
    "                            for dropout in dropouts:\n",
    "                                first_dropout = dropout == dropouts[0]\n",
    "                                for kernel_size in kernel_sizes:\n",
    "                                    first_kernel_size = kernel_size == kernel_sizes[0]\n",
    "                                    for kernel_try in kernel_tries:\n",
    "                                        first_kernel_try = kernel_try == kernel_tries[0]\n",
    "                                        for convolutional in convolutionals:\n",
    "                                            first_convolutional = convolutional == convolutionals[0]\n",
    "                                            for convolutional_activation in convolutional_activations:\n",
    "                                                first_convolutional_activation = convolutional_activation == convolutional_activations[0]\n",
    "                                                for max_pooling_size in max_pooling_sizes:\n",
    "                                                    first_max_pooling_size = max_pooling_size == max_pooling_sizes[0]\n",
    "                                                    # print(f\"max_pooling_size:  {max_pooling_size}\")\n",
    "                                                    # print(f\"convolutional:  {convolutional}\")\n",
    "                                                    # print(f\"kernel_try:  {kernel_try}\")\n",
    "                                                    # print(f\"kernel_size:  {kernel_size}\")\n",
    "                                                    # print(f\"dropout:  {dropout}\")\n",
    "                                                    # print(f\"node_num:  {node_num}\")\n",
    "                                                    # print(f\"layer:  {layer}\")\n",
    "                                                    # print(f\"batch_size:  {batch_size}\")\n",
    "                                                    # print(f\"epoch:  {epoch}\")\n",
    "                                                    parameters_dict = {\n",
    "                                                        'max_pooling_size': max_pooling_size,\n",
    "                                                        'convolutional_activation': convolutional_activation,\n",
    "                                                        'convolutional': convolutional,\n",
    "                                                        'kernel_try': kernel_try,\n",
    "                                                        'kernel_size': kernel_size,\n",
    "                                                        'dropout': dropout,\n",
    "                                                        'dense_activation': dense_activation,\n",
    "                                                        'node_variation': node_variation,\n",
    "                                                        'node_num': node_num,\n",
    "                                                        'layer': layer,\n",
    "                                                        'batch_size': batch_size,\n",
    "                                                        'epoch': epoch\n",
    "                                                    }\n",
    "                                                    parameters_list.append(parameters_dict)\n",
    "                                                    if not combine and (not first_convolutional_activation\n",
    "                                                                    or not first_convolutional \n",
    "                                                                    or not first_kernel_try \n",
    "                                                                    or not first_kernel_size \n",
    "                                                                    or not first_dropout \n",
    "                                                                    or not first_dense_activation \n",
    "                                                                    or not first_node_variation\n",
    "                                                                    or not first_node_num\n",
    "                                                                    or not first_layer\n",
    "                                                                    or not first_batch_size\n",
    "                                                                    or not first_epoch ):\n",
    "                                                        break\n",
    "                                                if not combine and (not first_convolutional\n",
    "                                                                    or not first_kernel_try \n",
    "                                                                    or not first_kernel_size \n",
    "                                                                    or not first_dropout \n",
    "                                                                    or not first_dense_activation \n",
    "                                                                    or not first_node_variation\n",
    "                                                                    or not first_node_num\n",
    "                                                                    or not first_layer\n",
    "                                                                    or not first_batch_size\n",
    "                                                                    or not first_epoch ):\n",
    "                                                    break\n",
    "                                            if not combine and (not first_kernel_try \n",
    "                                                                or not first_kernel_size \n",
    "                                                                or not first_dropout \n",
    "                                                                or not first_dense_activation \n",
    "                                                                or not first_node_variation\n",
    "                                                                or not first_node_num\n",
    "                                                                or not first_layer\n",
    "                                                                or not first_batch_size\n",
    "                                                                or not first_epoch ):\n",
    "                                                break\n",
    "                                        if not combine and (not first_kernel_size \n",
    "                                                            or not first_dropout \n",
    "                                                            or not first_dense_activation \n",
    "                                                            or not first_node_variation\n",
    "                                                            or not first_node_num\n",
    "                                                            or not first_layer\n",
    "                                                            or not first_batch_size\n",
    "                                                            or not first_epoch ):\n",
    "                                            break\n",
    "                                    if not combine and (not first_dropout \n",
    "                                                        or not first_dense_activation \n",
    "                                                        or not first_node_variation\n",
    "                                                        or not first_node_num\n",
    "                                                        or not first_layer\n",
    "                                                        or not first_batch_size\n",
    "                                                        or not first_epoch ):\n",
    "                                        break\n",
    "                                if not combine and (not first_dense_activation \n",
    "                                                    or not first_node_variation\n",
    "                                                    or not first_node_num\n",
    "                                                    or not first_layer\n",
    "                                                    or not first_batch_size\n",
    "                                                    or not first_epoch ):\n",
    "                                    break\n",
    "                            if not combine and ( not first_node_variation \n",
    "                                                or not first_node_num\n",
    "                                                or not first_layer\n",
    "                                                or not first_batch_size\n",
    "                                                or not first_epoch ):\n",
    "                                break\n",
    "                        if not combine and (not first_node_num\n",
    "                                            or not first_layer\n",
    "                                            or not first_batch_size\n",
    "                                            or not first_epoch):\n",
    "                            break\n",
    "                    if not combine and (not first_layer\n",
    "                                        or not first_batch_size\n",
    "                                        or not first_epoch ):\n",
    "                        break\n",
    "                if not combine and (not first_batch_size\n",
    "                                    or not first_epoch ):\n",
    "                    break\n",
    "            if not combine and not first_epoch:\n",
    "                break\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return parameters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(parameters):\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model. Assume that the\n",
    "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
    "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
    "    \"\"\"\n",
    "    print(parameters)\n",
    "\n",
    "    # Declare an empty list of layers to add to the model\n",
    "    layers = []\n",
    "\n",
    "    # Define the convolutional parameters and amount of layers\n",
    "    for i in range(parameters['convolutional']):\n",
    "        convolutional_layer = tf.keras.layers.Conv2D( filters=parameters['kernel_try'], \n",
    "                                        kernel_size=parameters['kernel_size'],\n",
    "                                        activation= parameters['convolutional_activation'],\n",
    "                                        input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "        layers.append(convolutional_layer)\n",
    "        pooling_layer = tf.keras.layers.MaxPooling2D((parameters['max_pooling_size'],parameters['max_pooling_size']))\n",
    "        layers.append(pooling_layer)\n",
    "\n",
    "    layers.append(tf.keras.layers.Flatten())\n",
    "\n",
    "    \n",
    "    layers_num = parameters['layer']\n",
    "\n",
    "    # We add the hidden layers with the specific nodes amount.\n",
    "    for i in range(layers_num):\n",
    "        nodes = parameters['node_num']\n",
    "        mean_nodes = round( nodes/layers_num, 0 )\n",
    "        if parameters['node_variation'] == 'equal':\n",
    "            nodes = mean_nodes\n",
    "        elif parameters['node_variation'] == 'ascending':\n",
    "            nodes = round( ( mean_nodes * i / ( layers_num - 1 ) ) + ( mean_nodes / 2 ), 0 )\n",
    "        elif parameters['node_variation'] == 'descending':\n",
    "            nodes = round( ( - mean_nodes * i / ( layers_num - 1 ) ) + ( mean_nodes / 2 + mean_nodes ), 0 )\n",
    "        elif parameters['node_variation'] == 'interleaved':\n",
    "            nodes = round( mean_nodes * 0.5 * ( i%2 * 2 - 1 ) + mean_nodes, 0 )\n",
    "        print(f\"layer: {i}, nodes: {nodes}\")\n",
    "        dense_layer = tf.keras.layers.Dense(nodes, activation=parameters['dense_activation'])\n",
    "        layers.append(dense_layer)\n",
    "    \n",
    "    # We add one dropout layer\n",
    "    dropout_layer = tf.keras.layers.Dropout(parameters['dropout'])\n",
    "    layers.append(dropout_layer)\n",
    "\n",
    "    # Finally we add the output layer\n",
    "    output_layer = tf.keras.layers.Dense(NUM_CATEGORIES, activation='softmax')\n",
    "    layers.append(output_layer)\n",
    "\n",
    "\n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_all_parameters(comb, splits = 1):\n",
    "\n",
    "\n",
    "    dict_list = []\n",
    "    for i in range(splits):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "        )\n",
    "        for parameters in comb:\n",
    "            model = get_model(parameters)\n",
    "            start = time.time()\n",
    "            model.fit(x_train, y_train, epochs=parameters['epoch'], batch_size=parameters['batch_size'])\n",
    "            end = time.time()\n",
    "\n",
    "            result = model.evaluate(x_test, y_test, verbose=1, return_dict=True)\n",
    "            result['time'] = end-start\n",
    "            result['efficiency'] = result['accuracy'] / ( X * result['time'] )\n",
    "            result = {**result, **parameters}\n",
    "            result['split_iteration'] = i\n",
    "            dict_list.append(result)\n",
    "\n",
    "    result_DataFrame = pd.DataFrame(dict_list)\n",
    "    return result_DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 30,\n",
       "  'epoch': 10},\n",
       " {'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 40,\n",
       "  'epoch': 10},\n",
       " {'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 50,\n",
       "  'epoch': 10},\n",
       " {'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 60,\n",
       "  'epoch': 10},\n",
       " {'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 30,\n",
       "  'epoch': 15},\n",
       " {'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 30,\n",
       "  'epoch': 20},\n",
       " {'max_pooling_size': 2,\n",
       "  'convolutional_activation': 'relu',\n",
       "  'convolutional': 1,\n",
       "  'kernel_try': 32,\n",
       "  'kernel_size': 3,\n",
       "  'dropout': 0.3,\n",
       "  'dense_activation': 'relu',\n",
       "  'node_variation': 'equal',\n",
       "  'node_num': 500,\n",
       "  'layer': 10,\n",
       "  'batch_size': 30,\n",
       "  'epoch': 25}]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = create_parameters_combination(   combine = False, \n",
    "                                        epochs = [10,15,20,25], # Choose one\n",
    "                                        batch_sizes = [30,40,50,60], # Choose one\n",
    "                                        layers = [10], \n",
    "                                        nodes = [500], \n",
    "                                        node_variations = ['equal'], \n",
    "                                        dense_activations = ['relu'],\n",
    "                                        dropouts = [0.3], \n",
    "                                        kernel_sizes = [3], \n",
    "                                        kernel_tries = [32], \n",
    "                                        convolutionals = [1],\n",
    "                                        convolutional_activations = ['relu'],\n",
    "                                        max_pooling_sizes = [2] )\n",
    "comb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_pooling_size': 2, 'convolutional_activation': 'relu', 'convolutional': 1, 'kernel_try': 64, 'kernel_size': 3, 'dropout': 0.3, 'dense_activation': 'relu', 'node_variation': 'interleaved', 'node_num': 100, 'layer': 5, 'batch_size': 50, 'epoch': 10}\n",
      "layer: 0, nodes: 10.0\n",
      "layer: 1, nodes: 30.0\n",
      "layer: 2, nodes: 10.0\n",
      "layer: 3, nodes: 30.0\n",
      "layer: 4, nodes: 10.0\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 10)                125450    \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 30)                330       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 30)                330       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 43)                473       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,995\n",
      "Trainable params: 128,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "320/320 [==============================] - 7s 17ms/step - loss: 3.7088 - accuracy: 0.0554\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 3.6166 - accuracy: 0.0575\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 5s 14ms/step - loss: 3.5654 - accuracy: 0.0575\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 5s 14ms/step - loss: 3.5359 - accuracy: 0.0575\n",
      "Epoch 5/10\n",
      "320/320 [==============================] - 5s 15ms/step - loss: 3.5194 - accuracy: 0.0575\n",
      "Epoch 6/10\n",
      "320/320 [==============================] - 5s 15ms/step - loss: 3.5101 - accuracy: 0.0575\n",
      "Epoch 7/10\n",
      "320/320 [==============================] - 5s 15ms/step - loss: 3.5050 - accuracy: 0.0575\n",
      "Epoch 8/10\n",
      "320/320 [==============================] - 5s 15ms/step - loss: 3.5020 - accuracy: 0.0575\n",
      "Epoch 9/10\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 3.5003 - accuracy: 0.0575\n",
      "Epoch 10/10\n",
      "320/320 [==============================] - 4s 14ms/step - loss: 3.4993 - accuracy: 0.0575\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 3.4996 - accuracy: 0.0545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>max_pooling_size</th>\n",
       "      <th>convolutional_activation</th>\n",
       "      <th>convolutional</th>\n",
       "      <th>kernel_try</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>dense_activation</th>\n",
       "      <th>node_variation</th>\n",
       "      <th>node_num</th>\n",
       "      <th>layer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epoch</th>\n",
       "      <th>split_iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.499572</td>\n",
       "      <td>0.054523</td>\n",
       "      <td>49.943514</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>relu</td>\n",
       "      <td>interleaved</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy       time  efficiency  max_pooling_size  \\\n",
       "0  3.499572  0.054523  49.943514    0.001092                 2   \n",
       "\n",
       "  convolutional_activation  convolutional  kernel_try  kernel_size  dropout  \\\n",
       "0                     relu              1          64            3      0.3   \n",
       "\n",
       "  dense_activation node_variation  node_num  layer  batch_size  epoch  \\\n",
       "0             relu    interleaved       100      5          50     10   \n",
       "\n",
       "   split_iteration  \n",
       "0                0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataframe = test_all_parameters(comb)\n",
    "result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
